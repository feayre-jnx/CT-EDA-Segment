{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training pipeline WITH image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import necessary libraries\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pydicom import dcmread\n",
    "import os\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from CT_Seg_Network.utils.dataset import *\n",
    "from CT_Seg_Network.models.Unet import UNet\n",
    "from CT_Seg_Network.utils.iou import IoU\n",
    "from CT_Seg_Network.utils.Loss import *\n",
    "from CT_Seg_Network.models.ResUnet import ResUNet\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the dataset images and save to another folder\n",
    "Processing:\n",
    "- conversion into Hounsfield Units\n",
    "- resampling into new spacing (optional)\n",
    "- normalization (i.e., remove unwanted labels such as bones (+700HU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load necessary functions\n",
    "\n",
    "## loads the scans per patient\n",
    "def load_scan(path, patient):\n",
    "    #slices = [dcmread(path + '/' + s) for s in os.listdir(path)]\n",
    "    \n",
    "    scanID, slices = [], []\n",
    "    patient_path = path + patient\n",
    "    for s in os.listdir(patient_path):\n",
    "        scanID.append(s[:-4])\n",
    "        slices.append(dcmread(patient_path + '/' + s))\n",
    "\n",
    "    \n",
    "    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "        \n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "        \n",
    "    return slices, scanID\n",
    "\n",
    "\n",
    "## converts the value into HU (Hounsfield Unit) and cleans out of bounds pixels\n",
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):\n",
    "        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "## resample to isotropic resolution to help convnets\n",
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = np.array([scan[0].SliceThickness] + list(scan[0].PixelSpacing), dtype=np.float32)\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
    "    \n",
    "    return image, new_spacing\n",
    "\n",
    "\n",
    "## remove values from unwanted body parts (e.g., bones +700HU)\n",
    "MIN_BOUND = -1000.0\n",
    "MAX_BOUND = 400.0\n",
    "    \n",
    "def normalize(image):\n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    image[image>1] = 1.\n",
    "    image[image<0] = 0.\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load each image and process as described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = 'coding_test_files/dicom_series/'\n",
    "PROCESSED_FOLDER = 'coding_test_files/processed_dicom/'\n",
    "patients = os.listdir(IMAGE_FOLDER)\n",
    "patients.sort()\n",
    "\n",
    "for pt in patients:\n",
    "    patient_scan, scanID = load_scan(IMAGE_FOLDER, pt)\n",
    "    patient_scan_pixels = get_pixels_hu(patient_scan)\n",
    "    #pix_resampled, spacing = resample(patient_scan_pixels, patient_scan, [1,1,1])\n",
    "    #patient_scan_pixels = pix_resampled\n",
    "\n",
    "    if not os.path.exists(PROCESSED_FOLDER + pt): \n",
    "        os.mkdir(PROCESSED_FOLDER + pt)\n",
    "\n",
    "    ## save the new images into processed folder\n",
    "    for i in range(patient_scan_pixels.shape[0]):\n",
    "        image = normalize(patient_scan_pixels[i,:,:])\n",
    "        np.savez_compressed(PROCESSED_FOLDER + pt + '/' + scanID[i], image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare the dataset by dividing the dataset into\n",
    "IMAGE_FOLDER = 'coding_test_files/processed_dicom/'\n",
    "SEG_FOLDER ='coding_test_files/segmentation_data/'\n",
    "patients = os.listdir(IMAGE_FOLDER)\n",
    "patients.sort()\n",
    "\n",
    "## split percentage\n",
    "percentage = .8\n",
    "train, val = np.split(patients, [int(len(patients)*percentage)])\n",
    "\n",
    "def load_list(folder, list_patients):\n",
    "    folder_list = []\n",
    "    for i in list_patients:\n",
    "        for j in os.listdir(folder + i):\n",
    "            folder_list.append(folder + i + '/' + j)\n",
    "    return folder_list\n",
    "\n",
    "train_list_im = load_list(IMAGE_FOLDER, train)\n",
    "val_list_im = load_list(IMAGE_FOLDER, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a dataset loader that will handle loading the images from processed dicom files directly\n",
    "## and labels from segmentation data\n",
    "\n",
    "class CSTO_CTDataset(Dataset):\n",
    "    def __init__(self, image_addr_list, seg_folder=None, transforms=None):\n",
    "\n",
    "        ## takes the address of the images\n",
    "        self.images = image_addr_list\n",
    "        if seg_folder == None:\n",
    "            self.seg_folder = 'coding_test_files/segmentation_data/'\n",
    "        else:\n",
    "            self.seg_folder = seg_folder\n",
    "\n",
    "        self.transform = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image_addr = self.images[idx]\n",
    "\n",
    "        img = np.load(image_addr)['arr_0']\n",
    "        img = np.expand_dims(img, axis=0).astype(np.float32)\n",
    "        img = torch.from_numpy(img).float()\n",
    "\n",
    "        ## extract the sample name from the image_name\n",
    "        last_slash = image_addr.find('processed_dicom/') + 16\n",
    "        sample = image_addr[last_slash:-4]\n",
    "        label_addr = self.seg_folder + sample +'.npz'\n",
    "        \n",
    "        if os.path.isfile(label_addr):\n",
    "            label = torch.from_numpy(np.transpose(np.load(label_addr)['arr_0'], (-1, 0, 1)))#.to(torch.float32)\n",
    "        else:\n",
    "            label = torch.zeros([4, img.shape[1], img.shape[2]])#.to(torch.float32)\n",
    "    \n",
    "        \n",
    "        if self.transform:\n",
    "            img, label = self.transform((img, label))\n",
    "\n",
    "        sample = {'img': img,\n",
    "                  'label': label}\n",
    "        \n",
    "        return sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load custom transforms that manipulates both image and label\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "            RandomFlip(),\n",
    "            Resize(128),\n",
    "            Normalize(mean=[0.5],\n",
    "                      std=[0.5])\n",
    "        ])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "            Resize(128),\n",
    "            Normalize(mean=[0.5],\n",
    "                      std=[0.5])\n",
    "        ])\n",
    "\n",
    "\n",
    "## create sets for train and validation\n",
    "trainset = CSTO_CTDataset(train_list_im, transforms=transform_train)\n",
    "valset = CSTO_CTDataset(val_list_im, transforms=transform_val)\n",
    "\n",
    "## create the dataloader for train and validation\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create functions for the training and evaluation proper\n",
    "\n",
    "def train(model,train_loader,optimizer,LOSS_FUNC,EPOCH,PRINT_INTERVAL, epoch, device):\n",
    "    losses = []\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        img, label = batch['img'].to(device), batch['label'].to(device)\n",
    "        output = model(img)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = LOSS_FUNC(output, label)\n",
    "\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        if (i + 1) % PRINT_INTERVAL == 0:\n",
    "            tqdm.write('Epoch [%d/%d], Iter [%d/%d], Loss: %.4f'\n",
    "                       % (epoch + 1, EPOCH, i + 1, len(train_loader), loss.item()))\n",
    "    return np.mean(losses)\n",
    "\n",
    "def eval(model,val_loader,LOSS_FUNC, device):\n",
    "    losses = []\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        img, label = batch['img'].to(device), batch['label'].to(device)\n",
    "        output = model(img)\n",
    "        loss = LOSS_FUNC(output, label)\n",
    "        losses.append(loss.item())\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set 3300\n",
      "Validation set 1103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 5/52 [00:13<02:02,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [5/52], Loss: 1.0399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 10/52 [00:26<01:51,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [10/52], Loss: 1.0474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 15/52 [00:40<01:40,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [15/52], Loss: 1.0328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 20/52 [00:53<01:27,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [20/52], Loss: 1.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 25/52 [01:07<01:13,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [25/52], Loss: 1.0340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 30/52 [01:21<01:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [30/52], Loss: 1.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 35/52 [01:34<00:46,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [35/52], Loss: 1.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 40/52 [01:48<00:33,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [40/52], Loss: 1.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 45/52 [02:02<00:19,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [45/52], Loss: 1.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 46/52 [02:05<00:16,  2.78s/it]"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "print(\"Train set {}\\nValidation set {}\".format(len(trainset),len(valset)))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## initialize model type\n",
    "model = ResUNet(out_classes=4).to(device)\n",
    "\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model).to(device)\n",
    "\n",
    "## init optimizer, scheduler, and loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "lr_sheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "LOSS_FUNC = DiceCELoss().to(device)\n",
    "PRINT_INTERVAL = 5\n",
    "EPOCH= 50\n",
    "\n",
    "\n",
    "\n",
    "## start training\n",
    "val_loss_epoch = []\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = train(model, trainloader, optimizer, LOSS_FUNC, EPOCH, PRINT_INTERVAL, epoch, device)\n",
    "    val_loss = eval(model, valloader, LOSS_FUNC, device)\n",
    "    val_loss_epoch.append(val_loss)\n",
    "    lr_sheduler.step()\n",
    "    tqdm.write('Epoch [%d/%d], Average Train Loss: %.4f, Average Validation Loss: %.4f'\n",
    "                % (epoch + 1, EPOCH, train_loss, val_loss))\n",
    "\n",
    "\n",
    "    ## save the model with the best val result\n",
    "    if val_loss == np.min(val_loss_epoch):\n",
    "        print('Model saved')\n",
    "        state = {\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        checkpoint_addr = 'CT_Seg_Network/weights/'\n",
    "        torch.save(state, os.path.join(checkpoint_addr,'best.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
