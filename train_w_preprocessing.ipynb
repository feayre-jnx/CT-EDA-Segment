{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training pipeline WITH image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import necessary libraries\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pydicom import dcmread\n",
    "import os\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from CT_Seg_Network.utils.dataset import *\n",
    "from CT_Seg_Network.models.Unet import UNet\n",
    "from CT_Seg_Network.utils.iou import IoU\n",
    "from CT_Seg_Network.utils.Loss import *\n",
    "from CT_Seg_Network.models.ResUnet import ResUNet\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the dataset images and save to another folder\n",
    "Processing:\n",
    "- conversion into Hounsfield Units\n",
    "- resampling into new spacing (optional)\n",
    "- normalization (i.e., remove unwanted labels such as bones (+700HU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load necessary functions\n",
    "\n",
    "## loads the scans per patient\n",
    "def load_scan(path, patient):\n",
    "    #slices = [dcmread(path + '/' + s) for s in os.listdir(path)]\n",
    "    \n",
    "    scanID, slices = [], []\n",
    "    patient_path = path + patient\n",
    "    for s in os.listdir(patient_path):\n",
    "        scanID.append(s[:-4])\n",
    "        slices.append(dcmread(patient_path + '/' + s))\n",
    "\n",
    "    \n",
    "    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "        \n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "        \n",
    "    return slices, scanID\n",
    "\n",
    "\n",
    "## converts the value into HU (Hounsfield Unit) and cleans out of bounds pixels\n",
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):\n",
    "        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "## resample to isotropic resolution to help convnets\n",
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = np.array([scan[0].SliceThickness] + list(scan[0].PixelSpacing), dtype=np.float32)\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
    "    \n",
    "    return image, new_spacing\n",
    "\n",
    "\n",
    "## remove values from unwanted body parts (e.g., bones +700HU)\n",
    "MIN_BOUND = -1000.0\n",
    "MAX_BOUND = 400.0\n",
    "    \n",
    "def normalize(image):\n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    image[image>1] = 1.\n",
    "    image[image<0] = 0.\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load each image and process as described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = 'coding_test_files/dicom_series/'\n",
    "PROCESSED_FOLDER = 'coding_test_files/processed_dicom/'\n",
    "patients = os.listdir(IMAGE_FOLDER)\n",
    "patients.sort()\n",
    "\n",
    "for pt in patients:\n",
    "    patient_scan, scanID = load_scan(IMAGE_FOLDER, pt)\n",
    "    patient_scan_pixels = get_pixels_hu(patient_scan)\n",
    "    #pix_resampled, spacing = resample(patient_scan_pixels, patient_scan, [1,1,1])\n",
    "    #patient_scan_pixels = pix_resampled\n",
    "\n",
    "    if not os.path.exists(PROCESSED_FOLDER + pt): \n",
    "        os.mkdir(PROCESSED_FOLDER + pt)\n",
    "\n",
    "    ## save the new images into processed folder\n",
    "    for i in range(patient_scan_pixels.shape[0]):\n",
    "        image = normalize(patient_scan_pixels[i,:,:])\n",
    "        np.savez_compressed(PROCESSED_FOLDER + pt + '/' + scanID[i], image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare the dataset by dividing the dataset into\n",
    "IMAGE_FOLDER = 'coding_test_files/processed_dicom/'\n",
    "SEG_FOLDER ='coding_test_files/segmentation_data/'\n",
    "patients = os.listdir(IMAGE_FOLDER)\n",
    "patients.sort()\n",
    "\n",
    "## split percentage\n",
    "percentage = .8\n",
    "train, val = np.split(patients, [int(len(patients)*percentage)])\n",
    "\n",
    "def load_list(folder, list_patients):\n",
    "    folder_list = []\n",
    "    for i in list_patients:\n",
    "        for j in os.listdir(folder + i):\n",
    "            folder_list.append(folder + i + '/' + j)\n",
    "    return folder_list\n",
    "\n",
    "train_list_im = load_list(IMAGE_FOLDER, train)\n",
    "val_list_im = load_list(IMAGE_FOLDER, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a dataset loader that will handle loading the images from processed dicom files directly\n",
    "## and labels from segmentation data\n",
    "\n",
    "class CSTO_CTDataset(Dataset):\n",
    "    def __init__(self, image_addr_list, seg_folder=None, transforms=None):\n",
    "\n",
    "        ## takes the address of the images\n",
    "        self.images = image_addr_list\n",
    "        if seg_folder == None:\n",
    "            self.seg_folder = 'coding_test_files/segmentation_data/'\n",
    "        else:\n",
    "            self.seg_folder = seg_folder\n",
    "\n",
    "        self.transform = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image_addr = self.images[idx]\n",
    "\n",
    "        img = np.load(image_addr)['arr_0']\n",
    "        img = np.expand_dims(img, axis=0).astype(np.float32)\n",
    "        img = torch.from_numpy(img).float()\n",
    "\n",
    "        ## extract the sample name from the image_name\n",
    "        last_slash = image_addr.find('processed_dicom/') + 16\n",
    "        sample = image_addr[last_slash:-4]\n",
    "        label_addr = self.seg_folder + sample +'.npz'\n",
    "        \n",
    "        if os.path.isfile(label_addr):\n",
    "            label = torch.from_numpy(np.transpose(np.load(label_addr)['arr_0'], (-1, 0, 1)))#.to(torch.float32)\n",
    "        else:\n",
    "            label = torch.zeros([4, img.shape[1], img.shape[2]])#.to(torch.float32)\n",
    "    \n",
    "        \n",
    "        if self.transform:\n",
    "            img, label = self.transform((img, label))\n",
    "\n",
    "        sample = {'img': img,\n",
    "                  'label': label}\n",
    "        \n",
    "        return sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load custom transforms that manipulates both image and label\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "            RandomFlip(),\n",
    "            Resize(128),\n",
    "            Normalize(mean=[0.5],\n",
    "                      std=[0.5])\n",
    "        ])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "            Resize(128),\n",
    "            Normalize(mean=[0.5],\n",
    "                      std=[0.5])\n",
    "        ])\n",
    "\n",
    "\n",
    "## create sets for train and validation\n",
    "trainset = CSTO_CTDataset(train_list_im, transforms=transform_train)\n",
    "valset = CSTO_CTDataset(val_list_im, transforms=transform_val)\n",
    "\n",
    "## create the dataloader for train and validation\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create functions for the training and evaluation proper\n",
    "\n",
    "def train(model,train_loader,optimizer,LOSS_FUNC,EPOCH,PRINT_INTERVAL, epoch, device):\n",
    "    losses = []\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        img, label = batch['img'].to(device), batch['label'].to(device)\n",
    "        output = model(img)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = LOSS_FUNC(output, label)\n",
    "\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        if (i + 1) % PRINT_INTERVAL == 0:\n",
    "            tqdm.write('Epoch [%d/%d], Iter [%d/%d], Loss: %.4f'\n",
    "                       % (epoch + 1, EPOCH, i + 1, len(train_loader), loss.item()))\n",
    "    return np.mean(losses)\n",
    "\n",
    "def eval(model,val_loader,LOSS_FUNC, device):\n",
    "    losses = []\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        img, label = batch['img'].to(device), batch['label'].to(device)\n",
    "        output = model(img)\n",
    "        loss = LOSS_FUNC(output, label)\n",
    "        losses.append(loss.item())\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set 3300\n",
      "Validation set 1103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 5/52 [00:13<02:02,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [5/52], Loss: 1.0399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 10/52 [00:26<01:51,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [10/52], Loss: 1.0474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 15/52 [00:40<01:40,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [15/52], Loss: 1.0328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 20/52 [00:53<01:27,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [20/52], Loss: 1.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 25/52 [01:07<01:13,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [25/52], Loss: 1.0340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 30/52 [01:21<01:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [30/52], Loss: 1.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 35/52 [01:34<00:46,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [35/52], Loss: 1.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 40/52 [01:48<00:33,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [40/52], Loss: 1.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 45/52 [02:02<00:19,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [45/52], Loss: 1.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 50/52 [02:16<00:05,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Iter [50/52], Loss: 1.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [02:20<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Average Train Loss: 1.0250, Average Validation Loss: 1.0235\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/52 [00:05<02:12,  2.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCH):\n\u001b[0;32m     28\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 29\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(model, trainloader, optimizer, LOSS_FUNC, EPOCH, PRINT_INTERVAL, epoch, device)\n\u001b[0;32m     30\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(model, valloader, LOSS_FUNC, device)\n\u001b[0;32m     31\u001b[0m     val_loss_epoch\u001b[38;5;241m.\u001b[39mappend(val_loss)\n",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, LOSS_FUNC, EPOCH, PRINT_INTERVAL, epoch, device)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model,train_loader,optimizer,LOSS_FUNC,EPOCH,PRINT_INTERVAL, epoch, device):\n\u001b[0;32m      4\u001b[0m     losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[0;32m      6\u001b[0m         img, label \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(img)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\medical_ai\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\medical_ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\medical_ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\medical_ai\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[28], line 34\u001b[0m, in \u001b[0;36mCSTO_CTDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     31\u001b[0m label_addr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseg_folder \u001b[38;5;241m+\u001b[39m sample \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(label_addr):\n\u001b[1;32m---> 34\u001b[0m     label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39mload(label_addr)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_0\u001b[39m\u001b[38;5;124m'\u001b[39m], (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\u001b[38;5;66;03m#.to(torch.float32)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros([\u001b[38;5;241m4\u001b[39m, img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]])\u001b[38;5;66;03m#.to(torch.float32)\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\medical_ai\\Lib\\site-packages\\numpy\\lib\\npyio.py:256\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mread_array(\u001b[38;5;28mbytes\u001b[39m,\n\u001b[0;32m    257\u001b[0m                              allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_pickle,\n\u001b[0;32m    258\u001b[0m                              pickle_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpickle_kwargs,\n\u001b[0;32m    259\u001b[0m                              max_header_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_header_size)\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\medical_ai\\Lib\\site-packages\\numpy\\lib\\format.py:831\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    829\u001b[0m             read_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_read_count, count \u001b[38;5;241m-\u001b[39m i)\n\u001b[0;32m    830\u001b[0m             read_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(read_count \u001b[38;5;241m*\u001b[39m dtype\u001b[38;5;241m.\u001b[39mitemsize)\n\u001b[1;32m--> 831\u001b[0m             data \u001b[38;5;241m=\u001b[39m _read_bytes(fp, read_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    832\u001b[0m             array[i:i\u001b[38;5;241m+\u001b[39mread_count] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    833\u001b[0m                                                      count\u001b[38;5;241m=\u001b[39mread_count)\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\medical_ai\\Lib\\site-packages\\numpy\\lib\\format.py:966\u001b[0m, in \u001b[0;36m_read_bytes\u001b[1;34m(fp, size, error_template)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[0;32m    964\u001b[0m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 966\u001b[0m         r \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(size \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(data))\n\u001b[0;32m    967\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[0;32m    968\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m size:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\medical_ai\\Lib\\zipfile\\__init__.py:981\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[1;32m--> 981\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read1(n)\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\medical_ai\\Lib\\zipfile\\__init__.py:1071\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1070\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1071\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_crc(data)\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\medical_ai\\Lib\\zipfile\\__init__.py:996\u001b[0m, in \u001b[0;36mZipExtFile._update_crc\u001b[1;34m(self, newdata)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;66;03m# No need to compute the CRC if we don't have a reference value\u001b[39;00m\n\u001b[0;32m    995\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 996\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m=\u001b[39m crc32(newdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc)\n\u001b[0;32m    997\u001b[0m \u001b[38;5;66;03m# Check the CRC if we're at the end of the file\u001b[39;00m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "print(\"Train set {}\\nValidation set {}\".format(len(trainset),len(valset)))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## initialize model type\n",
    "model = ResUNet(out_classes=4).to(device)\n",
    "\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model).to(device)\n",
    "\n",
    "## init optimizer, scheduler, and loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "lr_sheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "LOSS_FUNC = DiceCELoss().to(device)\n",
    "PRINT_INTERVAL = 5\n",
    "EPOCH= 50\n",
    "\n",
    "## start training\n",
    "val_loss_epoch = []\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = train(model, trainloader, optimizer, LOSS_FUNC, EPOCH, PRINT_INTERVAL, epoch, device)\n",
    "    val_loss = eval(model, valloader, LOSS_FUNC, device)\n",
    "    val_loss_epoch.append(val_loss)\n",
    "    lr_sheduler.step()\n",
    "    tqdm.write('Epoch [%d/%d], Average Train Loss: %.4f, Average Validation Loss: %.4f'\n",
    "                % (epoch + 1, EPOCH, train_loss, val_loss))\n",
    "\n",
    "\n",
    "    ## save the model with the best val result\n",
    "    if val_loss == np.min(val_loss_epoch):\n",
    "        print('Model saved')\n",
    "        state = {\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        checkpoint_addr = 'CT_Seg_Network/weights/'\n",
    "        torch.save(state, os.path.join(checkpoint_addr,'best.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
